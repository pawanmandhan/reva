{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41de8009",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6799ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2153cd",
   "metadata": {},
   "source": [
    "## Section 2: Define Problem Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41acf764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Parameters:\n",
      "======================================================================\n",
      "                Parameter Symbol  Value\n",
      "Claimed Mean Latency (μ₀)     μ₀ 200.00\n",
      "   Population Std Dev (σ)      σ  30.00\n",
      "          Sample Size (n)      n  64.00\n",
      "         Sample Mean (x̄)     x̄ 212.00\n",
      "   Significance Level (α)      α   0.05\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the problem parameters\n",
    "mu_0 = 200  # Claimed population mean latency (in ms)\n",
    "sigma = 30  # Population standard deviation (in ms)\n",
    "n = 64  # Sample size\n",
    "x_bar = 212  # Sample mean (in ms)\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Display the parameters in a nice table\n",
    "parameters = {\n",
    "    'Parameter': ['Claimed Mean Latency (μ₀)', 'Population Std Dev (σ)', 'Sample Size (n)', \n",
    "                  'Sample Mean (x̄)', 'Significance Level (α)'],\n",
    "    'Symbol': ['μ₀', 'σ', 'n', 'x̄', 'α'],\n",
    "    'Value': [mu_0, sigma, n, x_bar, alpha]\n",
    "}\n",
    "\n",
    "df_params = pd.DataFrame(parameters)\n",
    "print(\"Problem Parameters:\")\n",
    "print(\"=\" * 70)\n",
    "print(df_params.to_string(index=False))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a309c4",
   "metadata": {},
   "source": [
    "## Section 3: State Null and Alternative Hypotheses\n",
    "\n",
    "**Null Hypothesis (H₀):**\n",
    "$$H_0: \\mu = 200 \\text{ ms}$$\n",
    "\n",
    "The AI team's claim is that the mean inference latency is 200 ms.\n",
    "\n",
    "**Alternative Hypothesis (H₁):**\n",
    "$$H_1: \\mu \\neq 200 \\text{ ms}$$\n",
    "\n",
    "We are testing whether the mean inference latency is different from 200 ms (two-tailed test).\n",
    "\n",
    "**Test Type:** Two-tailed test (because we're testing if μ is not equal to 200)\n",
    "- **Rejection Region:** Both tails of the distribution\n",
    "- **Significance Level:** α = 0.05\n",
    "- **Each tail:** α/2 = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "758de845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPOTHESES SETUP\n",
      "======================================================================\n",
      "Null Hypothesis (H₀):          μ = 200 ms\n",
      "Alternative Hypothesis (H₁):   μ ≠ 200 ms\n",
      "\n",
      "Test Type: Two-tailed test\n",
      "Significance Level (α): 0.05\n",
      "Each tail (α/2): 0.025\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"HYPOTHESES SETUP\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Null Hypothesis (H₀):          μ = {mu_0} ms\")\n",
    "print(f\"Alternative Hypothesis (H₁):   μ ≠ {mu_0} ms\")\n",
    "print(f\"\\nTest Type: Two-tailed test\")\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print(f\"Each tail (α/2): {alpha/2}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39503961",
   "metadata": {},
   "source": [
    "## Section 4: Calculate the Test Statistic\n",
    "\n",
    "**Formula for Z-test statistic:**\n",
    "$$Z = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{x}$ = sample mean = 212 ms\n",
    "- $\\mu_0$ = hypothesized population mean = 200 ms\n",
    "- $\\sigma$ = population standard deviation = 30 ms\n",
    "- $n$ = sample size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eade25a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-TEST STATISTIC CALCULATION\n",
      "======================================================================\n",
      "Standard Error (SE) = σ / √n\n",
      "                   = 30 / √64\n",
      "                   = 30 / 8.0000\n",
      "                   = 3.7500\n",
      "\n",
      "Z-test Statistic = (x̄ - μ₀) / SE\n",
      "                 = (212 - 200) / 3.7500\n",
      "                 = 12 / 3.7500\n",
      "                 = 3.2000\n",
      "======================================================================\n",
      "\n",
      "✓ Calculated Z-statistic: 3.2000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard error\n",
    "standard_error = sigma / np.sqrt(n)\n",
    "\n",
    "# Calculate the Z-test statistic\n",
    "z_statistic = (x_bar - mu_0) / standard_error\n",
    "\n",
    "print(\"Z-TEST STATISTIC CALCULATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Standard Error (SE) = σ / √n\")\n",
    "print(f\"                   = {sigma} / √{n}\")\n",
    "print(f\"                   = {sigma} / {np.sqrt(n):.4f}\")\n",
    "print(f\"                   = {standard_error:.4f}\")\n",
    "print()\n",
    "print(f\"Z-test Statistic = (x̄ - μ₀) / SE\")\n",
    "print(f\"                 = ({x_bar} - {mu_0}) / {standard_error:.4f}\")\n",
    "print(f\"                 = {x_bar - mu_0} / {standard_error:.4f}\")\n",
    "print(f\"                 = {z_statistic:.4f}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n✓ Calculated Z-statistic: {z_statistic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc8665",
   "metadata": {},
   "source": [
    "## Section 5: Determine Critical Values and P-value\n",
    "\n",
    "For a two-tailed test at α = 0.05:\n",
    "- Each tail has an area of α/2 = 0.025\n",
    "- We need to find the critical Z-values where the cumulative probability is 0.025 and 0.975\n",
    "\n",
    "**Critical Z-values for α = 0.05 (two-tailed):**\n",
    "- Left critical value: Z_{α/2} = -Z_{0.025}\n",
    "- Right critical value: Z_{1-α/2} = Z_{0.975}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "317a3b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL VALUES AND P-VALUE\n",
      "======================================================================\n",
      "Significance Level (α): 0.05\n",
      "Each tail (α/2): 0.025\n",
      "\n",
      "Left Critical Value:  Z_{α/2} = -1.9600\n",
      "Right Critical Value: Z_{1-α/2} = 1.9600\n",
      "\n",
      "Rejection Regions:\n",
      "  - Reject H₀ if Z < -1.9600\n",
      "  - Reject H₀ if Z > 1.9600\n",
      "\n",
      "Two-Tailed P-value: 0.001374\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Find critical Z-values for two-tailed test\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)  # Right critical value\n",
    "z_critical_left = -z_critical  # Left critical value\n",
    "\n",
    "# Calculate the p-value (two-tailed)\n",
    "p_value = 2 * stats.norm.sf(abs(z_statistic))  # sf = survival function (1 - CDF)\n",
    "\n",
    "print(\"CRITICAL VALUES AND P-VALUE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print(f\"Each tail (α/2): {alpha/2}\")\n",
    "print()\n",
    "print(f\"Left Critical Value:  Z_{{α/2}} = {z_critical_left:.4f}\")\n",
    "print(f\"Right Critical Value: Z_{{1-α/2}} = {z_critical:.4f}\")\n",
    "print()\n",
    "print(f\"Rejection Regions:\")\n",
    "print(f\"  - Reject H₀ if Z < {z_critical_left:.4f}\")\n",
    "print(f\"  - Reject H₀ if Z > {z_critical:.4f}\")\n",
    "print()\n",
    "print(f\"Two-Tailed P-value: {p_value:.6f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9580604",
   "metadata": {},
   "source": [
    "## Section 6: Make a Decision\n",
    "\n",
    "**Decision Rules:**\n",
    "1. If |Z| > Z_{critical} → **Reject H₀**\n",
    "2. If p-value < α → **Reject H₀**\n",
    "3. Otherwise → **Fail to reject H₀**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a366448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DECISION ANALYSIS\n",
      "======================================================================\n",
      "Test Statistic (Z): 3.2000\n",
      "Critical Value (|Z|): ±1.9600\n",
      "P-value: 0.001374\n",
      "Significance Level (α): 0.05\n",
      "\n",
      "Decision Criteria 1 (Critical Value):\n",
      "  |Z| = |3.2000| = 3.2000\n",
      "  Critical Value = 1.9600\n",
      "  3.2000 > 1.9600? True\n",
      "\n",
      "Decision Criteria 2 (P-value):\n",
      "  P-value (0.001374) < α (0.05)? True\n",
      "\n",
      "======================================================================\n",
      "✓ DECISION: REJECT the null hypothesis (H₀)\n",
      "\n",
      "Conclusion: At the 0.05 level of significance,\n",
      "we have sufficient evidence to conclude that the mean\n",
      "inference latency is significantly different from 200 ms.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Make decision\n",
    "is_reject = abs(z_statistic) > z_critical\n",
    "\n",
    "print(\"\\nDECISION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Test Statistic (Z): {z_statistic:.4f}\")\n",
    "print(f\"Critical Value (|Z|): ±{z_critical:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print()\n",
    "print(f\"Decision Criteria 1 (Critical Value):\")\n",
    "print(f\"  |Z| = |{z_statistic:.4f}| = {abs(z_statistic):.4f}\")\n",
    "print(f\"  Critical Value = {z_critical:.4f}\")\n",
    "print(f\"  {abs(z_statistic):.4f} > {z_critical:.4f}? {abs(z_statistic) > z_critical}\")\n",
    "print()\n",
    "print(f\"Decision Criteria 2 (P-value):\")\n",
    "print(f\"  P-value ({p_value:.6f}) < α ({alpha})? {p_value < alpha}\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "if is_reject:\n",
    "    print(\"✓ DECISION: REJECT the null hypothesis (H₀)\")\n",
    "    print(f\"\\nConclusion: At the {alpha} level of significance,\")\n",
    "    print(\"we have sufficient evidence to conclude that the mean\")\n",
    "    print(\"inference latency is significantly different from 200 ms.\")\n",
    "else:\n",
    "    print(\"✗ DECISION: FAIL TO REJECT the null hypothesis (H₀)\")\n",
    "    print(f\"\\nConclusion: At the {alpha} level of significance,\")\n",
    "    print(\"we do not have sufficient evidence to conclude that the\")\n",
    "    print(\"mean inference latency is different from 200 ms.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3d578",
   "metadata": {},
   "source": [
    "## Section 7: Visualize the Hypothesis Test\n",
    "\n",
    "Let's create a comprehensive visualization showing:\n",
    "1. The standard normal distribution\n",
    "2. The rejection regions\n",
    "3. The critical values\n",
    "4. The calculated test statistic\n",
    "5. The p-value region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c53f1f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (844787709.py, line 91)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31max2.text(0.05, 0.95, summary_text, transform=ax2.transAxes, fontsize=10.5,\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Standard Normal Distribution with Critical Regions\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = stats.norm.pdf(x)\n",
    "\n",
    "ax1.plot(x, y, 'b-', linewidth=2.5, label='Standard Normal Distribution')\n",
    "\n",
    "# Fill rejection regions (tails)\n",
    "x_left = x[x <= z_critical_left]\n",
    "y_left = stats.norm.pdf(x_left)\n",
    "ax1.fill_between(x_left, y_left, alpha=0.3, color='red', label=f'Rejection Region (α/2 = {alpha/2})')\n",
    "\n",
    "x_right = x[x >= z_critical]\n",
    "y_right = stats.norm.pdf(x_right)\n",
    "ax1.fill_between(x_right, y_right, alpha=0.3, color='red')\n",
    "\n",
    "# Plot critical values\n",
    "ax1.axvline(z_critical_left, color='red', linestyle='--', linewidth=2, label=f'Critical Values: ±{z_critical:.4f}')\n",
    "ax1.axvline(z_critical, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Plot test statistic\n",
    "ax1.axvline(z_statistic, color='green', linestyle='-', linewidth=3, label=f'Test Statistic Z = {z_statistic:.4f}')\n",
    "\n",
    "# Shade p-value region\n",
    "x_p_value = x[x >= abs(z_statistic)]\n",
    "y_p_value = stats.norm.pdf(x_p_value)\n",
    "ax1.fill_between(x_p_value, y_p_value, alpha=0.2, color='orange', label=f'P-value area = {p_value:.6f}')\n",
    "\n",
    "# Add labels and formatting\n",
    "ax1.set_xlabel('Z-Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Probability Density', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Two-Tailed Z-Test: Critical Regions and Test Statistic', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-4, 4)\n",
    "\n",
    "# Add annotations\n",
    "ax1.annotate(f'Z = {z_critical_left:.4f}', xy=(z_critical_left, 0), xytext=(z_critical_left-0.5, 0.15),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'), fontsize=10, color='red', fontweight='bold')\n",
    "ax1.annotate(f'Z = {z_critical:.4f}', xy=(z_critical, 0), xytext=(z_critical+0.3, 0.15),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'), fontsize=10, color='red', fontweight='bold')\n",
    "ax1.annotate(f'Test Stat\\nZ = {z_statistic:.4f}', xy=(z_statistic, 0.1), xytext=(z_statistic-0.8, 0.35),\n",
    "            arrowprops=dict(arrowstyle='->', color='green'), fontsize=10, color='green', fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.7))\n",
    "\n",
    "# Plot 2: Summary Information\n",
    "ax2.axis('off')\n",
    "\n",
    "# Create summary text\n",
    "summary_text = f\"\"\"HYPOTHESIS TEST SUMMARY\n",
    "{'='*50}\n",
    "\n",
    "Problem: Model Inference Latency Testing\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Sample Information:\n",
    "  • Sample Size (n): {n}\n",
    "  • Sample Mean (x̄): {x_bar} ms\n",
    "  • Population Std Dev (σ): {sigma} ms\n",
    "  • Standard Error (SE): {standard_error:.4f} ms\n",
    "\n",
    "Hypotheses:\n",
    "  • H₀: μ = {mu_0} ms\n",
    "  • H₁: μ ≠ {mu_0} ms (Two-tailed)\n",
    "\n",
    "Test Statistics:\n",
    "  • Test Statistic (Z): {z_statistic:.4f}\n",
    "  • Critical Value (±): {z_critical:.4f}\n",
    "  • P-value: {p_value:.6f}\n",
    "  • Significance Level (α): {alpha}\n",
    "\n",
    "Decision Rule:\n",
    "  • Reject H₀ if |Z| > {z_critical:.4f}\n",
    "  • |{z_statistic:.4f}| > {z_critical:.4f}? {abs(z_statistic) > z_critical}\n",
    "  • P-value < {alpha}? {p_value < alpha}\n",
    "\n",
    "{'='*50}\n",
    "DECISION: {'REJECT H₀' if is_reject else 'FAIL TO REJECT H₀'}\n",
    "{'='*50}\n",
    "\n",
    "Interpretation:\n",
    "At the {alpha} level of significance, there is\n",
    "{'sufficient' if is_reject else 'insufficient'} evidence to conclude that\n",
    "the mean inference latency is {'SIGNIFICANTLY DIFFERENT' if is_reject else 'NOT significantly different'}\n",
    "from 200 ms.\n",
    "\n",
    "The sample provides {'strong' if is_reject else 'weak'} evidence against\n",
    "the AI team's claim.\"\"\"\n",
    "\n",
    "    ax2.text(0.05, 0.95, summary_text, transform=ax2.transAxes, fontsize=10.5,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_latency_hypothesis_test.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization saved as 'model_latency_hypothesis_test.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9122e18",
   "metadata": {},
   "source": [
    "## Final Summary and Conclusion\n",
    "\n",
    "### Test Results Summary\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Null Hypothesis** | μ = 200 ms |\n",
    "| **Alternative Hypothesis** | μ ≠ 200 ms |\n",
    "| **Test Type** | Two-Tailed Z-Test |\n",
    "| **Sample Size (n)** | 64 |\n",
    "| **Sample Mean (x̄)** | 212 ms |\n",
    "| **Population Std Dev (σ)** | 30 ms |\n",
    "| **Standard Error** | 3.75 ms |\n",
    "| **Calculated Z-Statistic** | 3.2 |\n",
    "| **Critical Z-Value (±)** | ±1.96 |\n",
    "| **P-Value** | 0.001371 |\n",
    "| **Significance Level (α)** | 0.05 |\n",
    "| **Decision** | **REJECT H₀** |\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "**At the 0.05 level of significance, we REJECT the null hypothesis.**\n",
    "\n",
    "This means there is **sufficient statistical evidence** to conclude that the mean inference latency of the deployed model is **significantly different from 200 milliseconds**.\n",
    "\n",
    "The sample mean of 212 ms provides strong evidence (Z = 3.2, p-value = 0.00137) that the true mean inference latency is not 200 ms. The p-value (0.00137) is much less than the significance level (0.05), confirming our decision to reject H₀.\n",
    "\n",
    "### Practical Interpretation\n",
    "\n",
    "The AI team's claim that the model has an average inference latency of 200 ms is rejected at the 5% significance level. The sample evidence suggests the actual mean latency is higher than claimed (212 ms observed vs 200 ms claimed).\n",
    "\n",
    "**Recommendation:** The model's inference latency should be investigated further, as it appears to exceed the claimed specification by approximately 12 milliseconds on average. This could indicate:\n",
    "- Need for model optimization\n",
    "- System performance issues\n",
    "- Changes in operational conditions since the claim was made"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
